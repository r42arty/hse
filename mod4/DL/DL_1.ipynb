{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/r42arty/hse/blob/main/mod4/DL/DL_1.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Основы машинного обучения, ИИМУП\n",
        "\n",
        "## НИУ ВШЭ, 2024-25 учебный год"
      ],
      "metadata": {
        "id": "uzoPPj-CT-hG"
      },
      "id": "uzoPPj-CT-hG"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VRUsuZR2cQoY"
      },
      "source": [
        "# Домашнее задание 1: Полносвязные нейронные сети"
      ],
      "id": "VRUsuZR2cQoY"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lV9pvgZJTYGj"
      },
      "source": [
        "Задание выполнил(а):\n",
        "\n",
        "    Рубцов Артемий"
      ],
      "id": "lV9pvgZJTYGj"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZML8VxlPTYGj"
      },
      "source": [
        "## Общая информация"
      ],
      "id": "ZML8VxlPTYGj"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nTmiXfZZTYGl"
      },
      "source": [
        "__Внимание!__  \n",
        "\n",
        "\n",
        "* Домашнее задание выполняется самостоятельно\n",
        "* Не допускается помощь в решении домашнего задания от однокурсников или третьих лиц. «Похожие» решения считаются плагиатом, и все задействованные студенты — в том числе и те, у кого списали, — не могут получить за него больше 0 баллов\n",
        "* Использование в решении домашнего задания генеративных моделей (ChatGPT и так далее) за рамками справочной и образовательной информации для генерации кода задания — считается плагиатом, и такое домашнее задание оценивается в 0 баллов\n",
        "* Старайтесь сделать код как можно более оптимальным. В частности, будет штрафоваться использование циклов в тех случаях, когда операцию можно совершить при помощи инструментов библиотек, о которых рассказывалось в курсе"
      ],
      "id": "nTmiXfZZTYGl"
    },
    {
      "cell_type": "markdown",
      "id": "lonely-delta",
      "metadata": {
        "id": "lonely-delta",
        "pycharm": {
          "name": "#%% md\n"
        }
      },
      "source": [
        "## О задании\n",
        "\n",
        "В этом задании вам предстоит обучить полносвязную нейронную сеть для предсказания года выпуска песни по ее аудио-признакам. Для этого мы будем использовать [Million Songs Dataset](https://samyzaf.com/ML/song_year/song_year.html)."
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Импорт библиотек и загрузка данных"
      ],
      "metadata": {
        "id": "qMsTUDdFCv-x"
      },
      "id": "qMsTUDdFCv-x"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "lonely-component",
      "metadata": {
        "id": "lonely-component",
        "pycharm": {
          "name": "#%%\n"
        }
      },
      "outputs": [],
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import seaborn as sns\n",
        "import torch\n",
        "\n",
        "from IPython.display import clear_output\n",
        "\n",
        "from sklearn.linear_model import Ridge\n",
        "from sklearn.metrics import mean_squared_error\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "\n",
        "from torch import nn\n",
        "from torch import optim\n",
        "from torch.utils.data import DataLoader, TensorDataset, random_split\n",
        "from tqdm.notebook import tqdm"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "plt.rcParams.update({\"font.size\": 16})\n",
        "sns.set_style(\"whitegrid\")\n",
        "np.random.seed(0xFA1AFE1)"
      ],
      "metadata": {
        "id": "lYtG-wqYCsqj"
      },
      "id": "lYtG-wqYCsqj",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "id": "marine-logistics",
      "metadata": {
        "id": "marine-logistics"
      },
      "source": [
        "Начнем с того, что скачаем и загрузим данные:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "bridal-archive",
      "metadata": {
        "id": "bridal-archive"
      },
      "outputs": [],
      "source": [
        "!wget -O data.txt.zip https://archive.ics.uci.edu/ml/machine-learning-databases/00203/YearPredictionMSD.txt.zip"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "welsh-heavy",
      "metadata": {
        "id": "welsh-heavy"
      },
      "outputs": [],
      "source": [
        "df = pd.read_csv(\"data.txt.zip\", header=None)\n",
        "df"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "single-hearts",
      "metadata": {
        "id": "single-hearts"
      },
      "source": [
        "Посмотрим на статистики по данным."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "interior-bacteria",
      "metadata": {
        "id": "interior-bacteria"
      },
      "outputs": [],
      "source": [
        "df.describe()"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "broad-writer",
      "metadata": {
        "id": "broad-writer"
      },
      "source": [
        "Целевая переменная, год выпуска песни, записана в первом столбце. Посмотрим на ее распределение."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "exposed-small",
      "metadata": {
        "id": "exposed-small"
      },
      "outputs": [],
      "source": [
        "plt.hist(df.iloc[:, 0], bins=20)\n",
        "plt.xlabel(\"year\")\n",
        "plt.ylabel(\"count\")\n",
        "plt.show()\n",
        "print(f\"Range: {df.iloc[:, 0].min()} - {df.iloc[:, 0].max()}\")\n",
        "print(f\"Unique values: {np.unique(df.iloc[:, 0]).size}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "noted-rebecca",
      "metadata": {
        "id": "noted-rebecca"
      },
      "source": [
        "Разобьем данные на обучение и тест (не меняйте здесь ничего, чтобы сплит был одинаковым у всех)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "presidential-wisconsin",
      "metadata": {
        "id": "presidential-wisconsin"
      },
      "outputs": [],
      "source": [
        "X = df.iloc[:, 1:].values\n",
        "y = df.iloc[:, 0].values\n",
        "\n",
        "train_size = int(0.75 * X.shape[0])\n",
        "X_train = X[:train_size, :]\n",
        "y_train = y[:train_size]\n",
        "X_test = X[train_size:, :]\n",
        "y_test = y[train_size:]\n",
        "X_train.shape, X_test.shape"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "adaptive-quantity",
      "metadata": {
        "id": "adaptive-quantity"
      },
      "source": [
        "**Задание 0 (0 баллов, но при невыполнении максимальная оценка за всю работу &mdash; 0 баллов).** Мы будем использовать MSE как метрику качества. Прежде чем обучать нейронные сети, нам нужно проверить несколько простых бейзлайнов, чтобы было с чем сравнить более сложные алгоритмы. Для этого бучите `Ridge` регрессию из `sklearn`. Кроме того, посчитайте качество при наилучшем константном прогнозе (также пропишите текстом, какая константа будет лучшей для MSE)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "mexican-fireplace",
      "metadata": {
        "id": "mexican-fireplace"
      },
      "outputs": [],
      "source": [
        "# Обучение Ridge-регрессии\n",
        "model = Ridge(alpha=1.0)\n",
        "model.fit(X_train, y_train)\n",
        "\n",
        "# Предсказание\n",
        "y_pred = model.predict(X_test)\n",
        "\n",
        "# Оценка Ridge\n",
        "mse_ridge = mean_squared_error(y_test, y_pred)\n",
        "\n",
        "print(f\"MSE модели: {mse_ridge:.1f}\")\n",
        "\n",
        "# Константный прогноз: среднее по y_train\n",
        "best_constant = y_train.mean()\n",
        "y_pred_const = np.full_like(y_test, fill_value=best_constant)\n",
        "\n",
        "mse_const = mean_squared_error(y_test, y_pred_const)\n",
        "print(f\"Наилучшая константа для MSE: {best_constant:.1f}\")\n",
        "print(f\"MSE для константного прогноза: {mse_const:.1f}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "0f4c6b65",
      "metadata": {
        "id": "0f4c6b65"
      },
      "source": [
        "**Ответ:**\n",
        "\n",
        "MSE модели: 89.7\n",
        "\n",
        "Наилучшая константа для MSE: 1998.4\n",
        "\n",
        "MSE для константного прогноза: 117.8"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "suspected-arbitration",
      "metadata": {
        "id": "suspected-arbitration"
      },
      "source": [
        "Теперь приступим к экспериментам с нейросетями. Для начала отделим от данных валидацию:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "offensive-publication",
      "metadata": {
        "id": "offensive-publication"
      },
      "outputs": [],
      "source": [
        "X_train, X_val, y_train, y_val = train_test_split(\n",
        "    X_train, y_train, test_size=0.25, random_state=0xE2E4\n",
        ")\n",
        "X_train.shape, X_val.shape"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "modern-platform",
      "metadata": {
        "id": "modern-platform"
      },
      "source": [
        "## Глава I. Заводим нейронную сеть (5 баллов)\n",
        "\n",
        "**Задание 1.1 (0.5 баллов).** Заполните пропуски в функции `train_and_validate`. Она поможет нам запускать эксперименты. Можете также реализовать поддержку обучения на GPU, чтобы эксперименты считались быстрее. Бесплатно воспользоваться GPU можно на сервисах **Google Colab** и **Kaggle**."
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "device = torch.accelerator.current_accelerator().type if torch.accelerator.is_available() else \"cpu\""
      ],
      "metadata": {
        "id": "FTHvINyQoQ1p"
      },
      "id": "FTHvINyQoQ1p",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "cooperative-bedroom",
      "metadata": {
        "id": "cooperative-bedroom"
      },
      "outputs": [],
      "source": [
        "def plot_losses(train_losses, train_metrics, val_losses, val_metrics):\n",
        "    \"\"\"\n",
        "    Plot losses and metrics while training\n",
        "      - train_losses: sequence of train losses\n",
        "      - train_metrics: sequence of train MSE values\n",
        "      - val_losses: sequence of validation losses\n",
        "      - val_metrics: sequence of validation MSE values\n",
        "    \"\"\"\n",
        "    clear_output()\n",
        "    fig, axs = plt.subplots(1, 2, figsize=(15, 5))\n",
        "    axs[0].plot(range(1, len(train_losses) + 1), train_losses, label=\"train\")\n",
        "    axs[0].plot(range(1, len(val_losses) + 1), val_losses, label=\"val\")\n",
        "    axs[1].plot(range(1, len(train_metrics) + 1), train_metrics, label=\"train\")\n",
        "    axs[1].plot(range(1, len(val_metrics) + 1), val_metrics, label=\"val\")\n",
        "\n",
        "    if max(train_losses) / min(train_losses) > 10:\n",
        "        axs[0].set_yscale(\"log\")\n",
        "\n",
        "    if max(train_metrics) / min(train_metrics) > 10:\n",
        "        axs[0].set_yscale(\"log\")\n",
        "\n",
        "    for ax in axs:\n",
        "        ax.set_xlabel(\"epoch\")\n",
        "        ax.legend()\n",
        "\n",
        "    axs[0].set_ylabel(\"loss\")\n",
        "    axs[1].set_ylabel(\"MSE\")\n",
        "    plt.show()\n",
        "\n",
        "\n",
        "def train_and_validate(\n",
        "    model,\n",
        "    optimizer,\n",
        "    criterion,\n",
        "    metric,\n",
        "    train_loader,\n",
        "    val_loader,\n",
        "    num_epochs,\n",
        "    verbose=True,\n",
        "):\n",
        "    \"\"\"\n",
        "    Train and validate neural network\n",
        "      - model: neural network to train\n",
        "      - optimizer: optimizer chained to a model\n",
        "      - criterion: loss function class\n",
        "      - metric: function to measure MSE taking neural networks predictions\n",
        "                 and ground truth labels\n",
        "      - train_loader: DataLoader with train set\n",
        "      - val_loader: DataLoader with validation set\n",
        "      - num_epochs: number of epochs to train\n",
        "      - verbose: whether to plot metrics during training\n",
        "    Returns:\n",
        "      - train_mse: training MSE over the last epoch\n",
        "      - val_mse: validation MSE after the last epoch\n",
        "    \"\"\"\n",
        "    train_losses, val_losses = [], []\n",
        "    train_metrics, val_metrics = [], []\n",
        "\n",
        "    for epoch in range(1, num_epochs + 1):\n",
        "        model.train()\n",
        "        running_loss, running_metric = 0, 0\n",
        "        pbar = (\n",
        "            tqdm(train_loader, desc=f\"Training {epoch}/{num_epochs}\")\n",
        "            if verbose\n",
        "            else train_loader\n",
        "        )\n",
        "\n",
        "        for i, (X_batch, y_batch) in enumerate(pbar, 1):\n",
        "            X_batch = X_batch.to(device)\n",
        "            y_batch = y_batch.to(device)\n",
        "\n",
        "            # Прямой проход\n",
        "            predictions = model(X_batch)\n",
        "            loss = criterion(predictions, y_batch)\n",
        "\n",
        "            # Обратный проход\n",
        "            optimizer.zero_grad()\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "\n",
        "            with torch.no_grad():\n",
        "                metric_value = metric(predictions, y_batch)\n",
        "                if type(metric_value) == torch.Tensor:\n",
        "                    metric_value = metric_value.item()\n",
        "                running_loss += loss.item() * X_batch.shape[0]\n",
        "                running_metric += metric_value * X_batch.shape[0]\n",
        "\n",
        "            if verbose and i % 100 == 0:\n",
        "                pbar.set_postfix({\"loss\": loss.item(), \"MSE\": metric_value})\n",
        "\n",
        "        train_losses += [running_loss / len(train_loader.dataset)]\n",
        "        train_metrics += [running_metric / len(train_loader.dataset)]\n",
        "\n",
        "        model.eval()\n",
        "        running_loss, running_metric = 0, 0\n",
        "        pbar = (\n",
        "            tqdm(val_loader, desc=f\"Validating {epoch}/{num_epochs}\")\n",
        "            if verbose\n",
        "            else val_loader\n",
        "        )\n",
        "\n",
        "        for i, (X_batch, y_batch) in enumerate(pbar, 1):\n",
        "            with torch.no_grad():\n",
        "                predictions = model(X_batch)\n",
        "                loss = criterion(predictions, y_batch)\n",
        "\n",
        "                metric_value = metric(predictions, y_batch)\n",
        "                if type(metric_value) == torch.Tensor:\n",
        "                    metric_value = metric_value.item()\n",
        "                running_loss += loss.item() * X_batch.shape[0]\n",
        "                running_metric += metric_value * X_batch.shape[0]\n",
        "\n",
        "            if verbose and i % 100 == 0:\n",
        "                pbar.set_postfix({\"loss\": loss.item(), \"MSE\": metric_value})\n",
        "\n",
        "        val_losses += [running_loss / len(val_loader.dataset)]\n",
        "        val_metrics += [running_metric / len(val_loader.dataset)]\n",
        "\n",
        "        if verbose:\n",
        "            plot_losses(train_losses, train_metrics, val_losses, val_metrics)\n",
        "\n",
        "    if verbose:\n",
        "        print(f\"Validation MSE: {val_metrics[-1]:.3f}\")\n",
        "\n",
        "    return train_metrics[-1], val_metrics[-1]"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "adjacent-grace",
      "metadata": {
        "id": "adjacent-grace"
      },
      "source": [
        "**Задание 1.2 (0.75 балла).** Попробуем обучить нашу первую нейронную сеть. Здесь целевая переменная дискретная &mdash; это год выпуска песни. Поэтому будем учить сеть на классификацию c помощью [кросс-энтропийной функции потерь](https://pytorch.org/docs/stable/generated/torch.nn.CrossEntropyLoss.html).\n",
        "\n",
        "- В качестве архитектуры сети возьмите два линейных слоя с активацией ReLU между ними c числом скрытых нейронов, равным 128.\n",
        "- Используйте SGD с `lr=1e-2`.\n",
        "- Возьмите размер мини-батча около 32-64, примерно 3-4 эпох обучения должно быть достаточно.\n",
        "- Скорее всего вам пригодится `torch.utils.data.TensorDataset`. Когда будете конвертировать numpy-массивы в torch-тензоры, используйте тип `torch.float32`.\n",
        "- Также преобразуйте целевую переменную так, чтобы ее значения принимали значения от $0$ до $C-1$, где $C$ &mdash; число классов (лучше передайте преобразованное значение в TensorDataset, исходное нам еще пригодится)\n",
        "- В качестве параметра `metric` в `train_and_validate` передайте lambda-выражение, которое считает MSE по выходу нейронной сети и целевой переменной. В случае классификации предсказывается класс с наибольшей вероятностью (или, что то же самое, с наибольшим значением **логита**$^1$).\n",
        "\n",
        "$^1$ **Логит** &mdash; выход последнего линейного слоя, может принимать любые вещественные значения. Если применить Softmax к логитам, то получатся вероятности распределения классов."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "manufactured-beverage",
      "metadata": {
        "id": "manufactured-beverage"
      },
      "outputs": [],
      "source": [
        "# Преобразуем y: года → метки от 0 до C-1\n",
        "le = LabelEncoder()\n",
        "y_class = le.fit_transform(y)\n",
        "num_classes = len(le.classes_)\n",
        "\n",
        "# Преобразуем данные в тензоры PyTorch\n",
        "X_tensor = torch.tensor(X, dtype=torch.float32).to(device)\n",
        "y_tensor = torch.tensor(y_class, dtype=torch.long).to(device)\n",
        "\n",
        "# Создаем датасет и делим его на обучающую и валидационную части\n",
        "dataset = TensorDataset(X_tensor, y_tensor)\n",
        "train_size = int(0.8 * len(dataset))\n",
        "val_size = len(dataset) - train_size\n",
        "train_ds, val_ds = random_split(dataset, [train_size, val_size])\n",
        "\n",
        "# Создаем даталоадеры\n",
        "train_loader = DataLoader(train_ds, batch_size=64, shuffle=True)\n",
        "val_loader = DataLoader(val_ds, batch_size=64)\n",
        "\n",
        "# Архитектура модели: 2 линейных слоя + ReLU\n",
        "model = nn.Sequential(\n",
        "    nn.Linear(X.shape[1], 128),\n",
        "    nn.ReLU(),\n",
        "    nn.Linear(128, num_classes)\n",
        ").to(device)\n",
        "\n",
        "# Оптимизатор и функция потерь\n",
        "optimizer = optim.SGD(model.parameters(), lr=1e-2)\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "\n",
        "# Метрика MSE\n",
        "metric = lambda logits, y_true: ((logits.argmax(dim=1) - y_true)**2).float().mean()\n",
        "\n",
        "# Запускаем обучение\n",
        "train_mse, val_mse = train_and_validate(\n",
        "    model=model,\n",
        "    optimizer=optimizer,\n",
        "    criterion=criterion,\n",
        "    metric=metric,\n",
        "    train_loader=train_loader,\n",
        "    val_loader=val_loader,\n",
        "    num_epochs=4,\n",
        "    verbose=True\n",
        ")\n",
        "\n",
        "print(f\"MSE_train: {train_mse:.2f}\")\n",
        "print(f\"MSE_val: {val_mse:.2f}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "postal-kingdom",
      "metadata": {
        "id": "postal-kingdom"
      },
      "source": [
        "**Задание 1.3 (0.5 балла).** Прокомментируйте ваши наблюдения. Удалось ли побить бейзлайн? Как вы думаете, хорошая ли идея учить классификатор для этой задачи? Почему?\n",
        "\n",
        "**Ответ:**\n",
        "\n",
        "Судя по графикам, обучение немного улучшило метрику на тренировке, но на валидации результат практически не изменился, что близко к бейзлайну. Это говорит о том, что модель не смогла извлечь полезные закономерности из данных.\n",
        "\n",
        "Бейзлайн не побит.\n",
        "Поскольку целевая переменная — год, а мы обучаем классификатор -- идея плохая. Предсказанный класс — это просто номер, а не реальное значение года."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "gorgeous-italy",
      "metadata": {
        "id": "gorgeous-italy"
      },
      "source": [
        "**Задание 1.4 (0.75 балла).** Теперь попробуем решать задачу как регрессию. Обучите нейронную сеть на [MSE](https://pytorch.org/docs/stable/generated/torch.nn.MSELoss.html).\n",
        "\n",
        "- Используйте такие же гиперпараметры обучения.\n",
        "- Когда передаете целевую переменную в TensorDataset, сделайте reshape в (-1, 1).\n",
        "- Не забудьте изменить lambda-выражение, которые вы передаете в `train_and_validate`.\n",
        "- Если что-то пойдет не так, можете попробовать меньшие значения `lr`."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "contrary-justice",
      "metadata": {
        "id": "contrary-justice"
      },
      "outputs": [],
      "source": [
        "# Преобразуем данные в тензоры PyTorch\n",
        "X_tensor = torch.tensor(X, dtype=torch.float32).to(device)\n",
        "y_tensor = torch.tensor(y.reshape(-1, 1), dtype=torch.float32).to(device)\n",
        "\n",
        "# Создаем датасет и делим его на обучающую и валидационную части\n",
        "dataset = TensorDataset(X_tensor, y_tensor)\n",
        "train_size = int(0.8 * len(dataset))\n",
        "val_size = len(dataset) - train_size\n",
        "train_ds, val_ds = random_split(dataset, [train_size, val_size])\n",
        "\n",
        "train_loader = DataLoader(train_ds, batch_size=64, shuffle=True)\n",
        "val_loader = DataLoader(val_ds, batch_size=64)\n",
        "\n",
        "# Запускаем модель\n",
        "model = nn.Sequential(\n",
        "    nn.Linear(X.shape[1], 128),\n",
        "    nn.ReLU(),\n",
        "    nn.Linear(128, 1)\n",
        ").to(device)\n",
        "\n",
        "# Оптимизатор и функция потерь\n",
        "optimizer = optim.SGD(model.parameters(), lr=1e-5)\n",
        "criterion = nn.MSELoss()\n",
        "\n",
        "# Метрика MSE\n",
        "metric = lambda pred, y: ((pred - y) ** 2).mean().item()\n",
        "\n",
        "# Запускаем обучение\n",
        "train_mse, val_mse = train_and_validate(\n",
        "    model=model,\n",
        "    optimizer=optimizer,\n",
        "    criterion=criterion,\n",
        "    metric=metric,\n",
        "    train_loader=train_loader,\n",
        "    val_loader=val_loader,\n",
        "    num_epochs=4\n",
        ")\n",
        "\n",
        "print(f\"MSE_train: {train_mse:.2f}\")\n",
        "print(f\"MSE_val: {val_mse:.2f}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "nonprofit-passenger",
      "metadata": {
        "id": "nonprofit-passenger"
      },
      "source": [
        "**Задание 1.5 (0.5 балла).** Получилось ли у вас стабилизировать обучение? Помогли ли меньшие значения `lr`? Стало ли лучше от замены классификации на регрессию? Как вы думаете, почему так происходит? В качестве подсказки можете посмотреть на распределение целевой переменной и магнитуду значений признаков.\n",
        "\n",
        "**Ответ:**\n",
        "\n",
        "Стабилизации обучения не произошло — значения MSE остаются гигантскими (millions), несмотря на падение loss.\n",
        "Замена классификации на регрессию пока не улучшила результат, а даже ухудшила его (по сравнению с классификатором MSE ~193).\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "tested-cleaners",
      "metadata": {
        "id": "tested-cleaners"
      },
      "source": [
        "**Задание 1.6 (0.75 балла).** Начнем с того, что попробуем отнормировать целевую переменную. Для этого воспользуемся min-max нормализацией, чтобы целевая переменная принимала значения от 0 до 1. Реализуйте функции `normalize` и `denormalize`, которые, соответственно, нормируют целевую переменную и применяют обратное преобразование. Минимум и максимум оцените по обучающей выборке (то есть эти константы должны быть фиксированными и не зависеть от передаваемой выборки)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "downtown-stake",
      "metadata": {
        "id": "downtown-stake"
      },
      "outputs": [],
      "source": [
        "scaler = StandardScaler()\n",
        "\n",
        "def normalize(sample):\n",
        "  return scaler.fit_transform(y.reshape(-1, 1)).flatten()\n",
        "\n",
        "def denormalize(sample):\n",
        "  return scaler.inverse_transform(y_norm.reshape(-1, 1)).flatten()"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "official-booking",
      "metadata": {
        "id": "official-booking"
      },
      "source": [
        "Теперь повторите эксперимент из **задания 1.4**, обучаясь на нормированной целевой переменной. Сделаем также еще одно изменение: добавим [сигмоидную активацию](https://pytorch.org/docs/stable/generated/torch.nn.Sigmoid.html) после последнего линейного слоя сети. Таким образом мы гарантируем, что нейронная сеть предсказывает числа из промежутка $[0, 1]$. Использование активации - довольно распространенный прием, когда мы хотим получить числа из определенного диапазона значений."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "olive-brick",
      "metadata": {
        "id": "olive-brick"
      },
      "outputs": [],
      "source": [
        "# Проведем нормализацию\n",
        "y_norm = normalize(y)\n",
        "\n",
        "# Преобразуем данные в тензоры PyTorch\n",
        "X_tensor = torch.tensor(X, dtype=torch.float32).to(device)\n",
        "y_tensor = torch.tensor(y_norm.reshape(-1, 1), dtype=torch.float32).to(device)\n",
        "\n",
        "# Создаем датасет и делим его на обучающую и валидационную части\n",
        "dataset = TensorDataset(X_tensor, y_tensor)\n",
        "train_size = int(0.8 * len(dataset))\n",
        "val_size = len(dataset) - train_size\n",
        "train_ds, val_ds = random_split(dataset, [train_size, val_size])\n",
        "\n",
        "train_loader = DataLoader(train_ds, batch_size=64, shuffle=True)\n",
        "val_loader = DataLoader(val_ds, batch_size=64)\n",
        "\n",
        "# Запускаем модель\n",
        "model = nn.Sequential(\n",
        "    nn.Linear(X.shape[1], 128),\n",
        "    nn.ReLU(),\n",
        "    nn.Linear(128, 1),\n",
        "    nn.Sigmoid()\n",
        ").to(device)\n",
        "\n",
        "# Оптимизатор и функция потерь\n",
        "optimizer = optim.SGD(model.parameters(), lr=1e-2)\n",
        "criterion = nn.MSELoss()\n",
        "\n",
        "# Метрика MSE\n",
        "metric = lambda pred, y: ((pred - y) ** 2).mean().item()\n",
        "\n",
        "# Запускаем обучение\n",
        "train_mse, val_mse = train_and_validate(\n",
        "    model=model,\n",
        "    optimizer=optimizer,\n",
        "    criterion=criterion,\n",
        "    metric=metric,\n",
        "    train_loader=train_loader,\n",
        "    val_loader=val_loader,\n",
        "    num_epochs=4\n",
        ")\n",
        "\n",
        "print(f\"MSE_train: {train_mse:.2f}\")\n",
        "print(f\"MSE_val: {val_mse:.2f}\")\n",
        "\n",
        "# Проведем денормализацию\n",
        "model.eval()\n",
        "X_val_batch, y_val_batch = next(iter(val_loader))\n",
        "X_val_batch = X_val_batch.to(device)\n",
        "with torch.no_grad():\n",
        "    y_pred_norm = model(X_val_batch).squeeze().cpu().numpy()\n",
        "\n",
        "y_pred_real = denormalize(y_pred_norm)\n",
        "y_val_real = denormalize(y_val_batch.squeeze().cpu().numpy())\n",
        "\n",
        "val_mse_real = np.mean((y_pred_real - y_val_real) ** 2)\n",
        "print(f\"MSE_val (в годах): {val_mse_real:.2f}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "twenty-pulse",
      "metadata": {
        "id": "twenty-pulse"
      },
      "source": [
        "**Задание 1.7 (0.5 балла).** Сравните результаты этого эксперимента с предыдущим запуском.\n",
        "\n",
        "**Ответ:**\n",
        "\n",
        "Графики loss и MSE стали гладкими и стабильными, без взрывов или резких скачков."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "colonial-slovakia",
      "metadata": {
        "id": "colonial-slovakia"
      },
      "source": [
        "**Задание 1.8 (0.75 балла).** На этот раз попробуем отнормировать не только целевую переменную, но и сами данные, которые подаются сети на вход. Для них будем использовать нормализацию через среднее и стандартное отклонение. Преобразуйте данные и повторите прошлый эксперимент. Скорее всего, имеет смысл увеличить число эпох обучения."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "prospective-disabled",
      "metadata": {
        "id": "prospective-disabled"
      },
      "outputs": [],
      "source": [
        "# Проведем нормализацию\n",
        "X_mean = X.mean(axis=0)\n",
        "X_std = X.std(axis=0) + 1e-8\n",
        "X_norm = (X - X_mean) / X_std\n",
        "\n",
        "y_norm = normalize(y)\n",
        "\n",
        "# Преобразуем данные в тензоры PyTorch\n",
        "X_tensor = torch.tensor(X_norm, dtype=torch.float32).to(device)\n",
        "y_tensor = torch.tensor(y_norm.reshape(-1, 1), dtype=torch.float32).to(device)\n",
        "\n",
        "# Создаем датасет и делим его на обучающую и валидационную части\n",
        "dataset = TensorDataset(X_tensor, y_tensor)\n",
        "train_size = int(0.8 * len(dataset))\n",
        "val_size = len(dataset) - train_size\n",
        "train_ds, val_ds = random_split(dataset, [train_size, val_size])\n",
        "\n",
        "train_loader = DataLoader(train_ds, batch_size=64, shuffle=True)\n",
        "val_loader = DataLoader(val_ds, batch_size=64)\n",
        "\n",
        "# Запускаем модель\n",
        "model = nn.Sequential(\n",
        "    nn.Linear(X.shape[1], 128),\n",
        "    nn.ReLU(),\n",
        "    nn.Linear(128, 1),\n",
        "    nn.Sigmoid()\n",
        ").to(device)\n",
        "\n",
        "# Оптимизатор и функция потерь\n",
        "optimizer = optim.SGD(model.parameters(), lr=1e-2)\n",
        "criterion = nn.MSELoss()\n",
        "\n",
        "# Метрика MSE\n",
        "metric = lambda pred, y: ((pred - y) ** 2).mean().item()\n",
        "\n",
        "# Запускаем обучение\n",
        "train_mse, val_mse = train_and_validate(\n",
        "    model=model,\n",
        "    optimizer=optimizer,\n",
        "    criterion=criterion,\n",
        "    metric=metric,\n",
        "    train_loader=train_loader,\n",
        "    val_loader=val_loader,\n",
        "    num_epochs=10\n",
        ")\n",
        "\n",
        "print(f\"MSE_train: {train_mse:.4f}\")\n",
        "print(f\"MSE_val: {val_mse:.4f}\")\n",
        "\n",
        "# Проведем денормализацию\n",
        "model.eval()\n",
        "X_val_batch, y_val_batch = next(iter(val_loader))\n",
        "X_val_batch = X_val_batch.to(device)\n",
        "with torch.no_grad():\n",
        "    y_pred_norm = model(X_val_batch).squeeze().cpu().numpy()\n",
        "\n",
        "y_pred_real = denormalize(y_pred_norm)\n",
        "y_val_real = denormalize(y_val_batch.squeeze().cpu().numpy())\n",
        "\n",
        "val_mse_real = np.mean((y_pred_real - y_val_real) ** 2)\n",
        "print(f\"MSE_val (в годах): {val_mse_real:.2f}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "opponent-decision",
      "metadata": {
        "id": "opponent-decision"
      },
      "source": [
        "Если вы все сделали правильно, то у вас должно было получиться качество, сравнимое с `Ridge` регрессией.\n",
        "\n",
        "**Мораль:** как видите, нам пришлось сделать очень много хитрых телодвижений, чтобы нейронная сеть работала хотя бы так же, как и простая линейная модель. Здесь, конечно, показан совсем экстремальный случай, когда без нормализации данных нейронная сеть просто не учится. Как правило, в реальности завести нейронную сеть из коробки не очень сложно, но вот заставить ее работать на полную &mdash; куда более трудоемкая задача. Написание пайплайнов обучения нейросетевых моделей требует большой аккуратности, а дебаг часто превращается в угадайку. К счастью, очень часто на помощь приходит интуиция, и мы надеемся, что вы сможете выработать ее со временем!\n",
        "\n",
        "Начнем с двух советов, которые стоит принять на вооружение:\n",
        "\n",
        "- Обязательно начинаем любые эксперименты с бейзлайнов: без них мы бы не поняли, что нейронная сеть не учится в принципе\n",
        "- При постановке эксперментов старайтесь делать минимальное количество изменений за раз (в идеале одно!): только так можно понять, какие конкретно изменения влияют на результат"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "royal-cholesterol",
      "metadata": {
        "id": "royal-cholesterol"
      },
      "source": [
        "## Часть 2. Улучшаем нейронную сеть (5 баллов)\n",
        "\n",
        "Продолжим экспериментировать с нейронной сетью, чтобы добиться еще лучшего качества."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "ignored-active",
      "metadata": {
        "id": "ignored-active"
      },
      "source": [
        "**Задание 2.1 (1 балл).** Давайте попробуем другие оптимизаторы. Обучите нейросеть с помощью SGD+momentum и Adam. Опишите свои наблюдения и в дальнейших запусках используйте лучший оптимизатор. Для Adam обычно берут learning rate поменьше, в районе $10^{-3}$."
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## sgd + momentum"
      ],
      "metadata": {
        "id": "EV45Speu6jkX"
      },
      "id": "EV45Speu6jkX"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "eastern-gnome",
      "metadata": {
        "id": "eastern-gnome"
      },
      "outputs": [],
      "source": [
        "model_sgd_momentum = nn.Sequential(\n",
        "    nn.Linear(X.shape[1], 128),\n",
        "    nn.ReLU(),\n",
        "    nn.Linear(128, 1),\n",
        "    nn.Sigmoid()\n",
        ")\n",
        "\n",
        "optimizer_sgd_momentum = optim.SGD(model_sgd_momentum.parameters(), lr=1e-2, momentum=0.9)\n",
        "\n",
        "train_mse_sgd, val_mse_sgd = train_and_validate(\n",
        "    model=model_sgd_momentum,\n",
        "    optimizer=optimizer_sgd_momentum,\n",
        "    criterion=criterion,\n",
        "    metric=metric,\n",
        "    train_loader=train_loader,\n",
        "    val_loader=val_loader,\n",
        "    num_epochs=10\n",
        ")\n",
        "\n",
        "print(f\"[SGD + momentum] MSE_train: {train_mse_sgd:.4f}\")\n",
        "print(f\"[SGD + momentum] MSE_val: {val_mse_sgd:.4f}\")\n",
        "\n",
        "model_sgd_momentum.eval()\n",
        "X_val_batch, y_val_batch = next(iter(val_loader))\n",
        "X_val_batch = X_val_batch.to(device)\n",
        "with torch.no_grad():\n",
        "    y_pred_norm = model_sgd_momentum(X_val_batch).squeeze().cpu().numpy()\n",
        "\n",
        "y_pred_real = denormalize(y_pred_norm)\n",
        "y_val_real = denormalize(y_val_batch.squeeze().cpu().numpy())\n",
        "\n",
        "val_mse_real_sgd = np.mean((y_pred_real - y_val_real) ** 2)\n",
        "print(f\"[SGD + momentum] MSE_val (в годах): {val_mse_real_sgd:.2f}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Adam"
      ],
      "metadata": {
        "id": "5UrT1Bsk6lry"
      },
      "id": "5UrT1Bsk6lry"
    },
    {
      "cell_type": "code",
      "source": [
        "model_adam = nn.Sequential(\n",
        "    nn.Linear(X.shape[1], 128),\n",
        "    nn.ReLU(),\n",
        "    nn.Linear(128, 1),\n",
        "    nn.Sigmoid()\n",
        ").to(device)\n",
        "\n",
        "optimizer_adam = optim.Adam(model_adam.parameters(), lr=1e-3)\n",
        "\n",
        "train_mse_adam, val_mse_adam = train_and_validate(\n",
        "    model=model_adam,\n",
        "    optimizer=optimizer_adam,\n",
        "    criterion=criterion,\n",
        "    metric=metric,\n",
        "    train_loader=train_loader,\n",
        "    val_loader=val_loader,\n",
        "    num_epochs=10\n",
        ")\n",
        "\n",
        "print(f\"[Adam] MSE_train: {train_mse_adam:.4f}\")\n",
        "print(f\"[Adam] MSE_val: {val_mse_adam:.4f}\")\n",
        "\n",
        "# Денормализация и подсчёт MSE в годах\n",
        "model_adam.eval()\n",
        "X_val_batch, y_val_batch = next(iter(val_loader))\n",
        "X_val_batch = X_val_batch.to(device)\n",
        "with torch.no_grad():\n",
        "    y_pred_norm = model_adam(X_val_batch).squeeze().cpu().numpy()\n",
        "\n",
        "y_pred_real = denormalize(y_pred_norm)\n",
        "y_val_real = denormalize(y_val_batch.squeeze().cpu().numpy())\n",
        "\n",
        "val_mse_real_adam = np.mean((y_pred_real - y_val_real) ** 2)\n",
        "print(f\"[Adam] MSE_val (в годах): {val_mse_real_adam:.2f}\")"
      ],
      "metadata": {
        "id": "4kCHzuQV6Z1z"
      },
      "id": "4kCHzuQV6Z1z",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "id": "hispanic-postage",
      "metadata": {
        "id": "hispanic-postage"
      },
      "source": [
        "**Задание 2.2 (1 балл).** Теперь сделаем нашу нейронную сеть более сложной. Попробуйте сделать сеть:\n",
        "\n",
        "- более широкой (то есть увеличить размерность скрытого слоя, например, вдвое)\n",
        "- более глубокой (то есть добавить еще один скрытый слой)\n",
        "\n",
        "Опишите, как увеличение числа параметров модели влияет на качество на обучающей и валидационной выборках."
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Более широкий вариант"
      ],
      "metadata": {
        "id": "y_tbkG7G7IgW"
      },
      "id": "y_tbkG7G7IgW"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "1d466362",
      "metadata": {
        "id": "1d466362"
      },
      "outputs": [],
      "source": [
        "model_wide = nn.Sequential(\n",
        "    nn.Linear(X.shape[1], 256),\n",
        "    nn.ReLU(),\n",
        "    nn.Linear(256, 1),\n",
        "    nn.Sigmoid()\n",
        ").to(device)\n",
        "\n",
        "optimizer_wide = optim.Adam(model_wide.parameters(), lr=1e-3)\n",
        "\n",
        "train_mse_wide, val_mse_wide = train_and_validate(\n",
        "    model=model_wide,\n",
        "    optimizer=optimizer_wide,\n",
        "    criterion=criterion,\n",
        "    metric=metric,\n",
        "    train_loader=train_loader,\n",
        "    val_loader=val_loader,\n",
        "    num_epochs=10\n",
        ")\n",
        "\n",
        "print(f\"[Wide model] MSE_val: {val_mse_wide:.4f}\")\n",
        "\n",
        "model_wide.eval()\n",
        "X_val_batch, y_val_batch = next(iter(val_loader))\n",
        "X_val_batch = X_val_batch.to(device)\n",
        "with torch.no_grad():\n",
        "    y_pred_norm = model_wide(X_val_batch).squeeze().cpu().numpy()\n",
        "\n",
        "y_pred_real = denormalize(y_pred_norm)\n",
        "y_val_real = denormalize(y_val_batch.squeeze().cpu().numpy())\n",
        "val_mse_real_wide = np.mean((y_pred_real - y_val_real) ** 2)\n",
        "print(f\"[Wide model] MSE_val (в годах): {val_mse_real_wide:.2f}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Модель с новым скрытым слоем"
      ],
      "metadata": {
        "id": "C44UuAFS7YHF"
      },
      "id": "C44UuAFS7YHF"
    },
    {
      "cell_type": "code",
      "source": [
        "model_deep = nn.Sequential(\n",
        "    nn.Linear(X.shape[1], 128),\n",
        "    nn.ReLU(),\n",
        "    nn.Linear(128, 64),\n",
        "    nn.ReLU(),\n",
        "    nn.Linear(64, 1),\n",
        "    nn.Sigmoid()\n",
        ").to(device)\n",
        "\n",
        "optimizer_deep = optim.Adam(model_deep.parameters(), lr=1e-3)\n",
        "\n",
        "train_mse_deep, val_mse_deep = train_and_validate(\n",
        "    model=model_deep,\n",
        "    optimizer=optimizer_deep,\n",
        "    criterion=criterion,\n",
        "    metric=metric,\n",
        "    train_loader=train_loader,\n",
        "    val_loader=val_loader,\n",
        "    num_epochs=10\n",
        ")\n",
        "\n",
        "print(f\"[Deep model] MSE_val: {val_mse_deep:.4f}\")\n",
        "\n",
        "model_deep.eval()\n",
        "X_val_batch, y_val_batch = next(iter(val_loader))\n",
        "X_val_batch = X_val_batch.to(device)\n",
        "\n",
        "with torch.no_grad():\n",
        "    y_pred_norm = model_deep(X_val_batch).squeeze().cpu().numpy()\n",
        "\n",
        "y_pred_real = denormalize(y_pred_norm)\n",
        "y_val_real = denormalize(y_val_batch.squeeze().cpu().numpy())\n",
        "val_mse_real_deep = np.mean((y_pred_real - y_val_real) ** 2)\n",
        "print(f\"[Deep model] MSE_val (в годах): {val_mse_real_deep:.2f}\")"
      ],
      "metadata": {
        "id": "PWotgaWb7axM"
      },
      "id": "PWotgaWb7axM",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Вывод**: Судя по графикам есть переобучение у обоих моделей"
      ],
      "metadata": {
        "id": "N3But8Bo7uXx"
      },
      "id": "N3But8Bo7uXx"
    },
    {
      "cell_type": "markdown",
      "id": "454acdb1",
      "metadata": {
        "id": "454acdb1"
      },
      "source": [
        "**Задание 2.3 (1 балл).** Как вы должны были заметить, более сложная модель стала сильнее переобучаться. Попробуем добавить в обучение регуляризацию, чтобы бороться с переобучением. Добавьте слой дропаута ([`nn.Dropout`](https://pytorch.org/docs/stable/generated/torch.nn.Dropout.html#torch.nn.Dropout)) с параметром $p=0.2$ после каждого линейного слоя, кроме последнего. Почитать про дропаут можете в следующем [блогпосте](https://medium.com/@amarbudhiraja/https-medium-com-amarbudhiraja-learning-less-to-learn-better-dropout-in-deep-machine-learning-74334da4bfc5) или в оригинальной [статье](https://jmlr.org/papers/volume15/srivastava14a/srivastava14a.pdf)\n",
        "\n",
        "Опишите результаты."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "483a941a",
      "metadata": {
        "id": "483a941a"
      },
      "outputs": [],
      "source": [
        "model_deep_dropout = nn.Sequential(\n",
        "    nn.Linear(X.shape[1], 128),\n",
        "    nn.ReLU(),\n",
        "    nn.Dropout(p=0.2),\n",
        "    nn.Linear(128, 64),\n",
        "    nn.ReLU(),\n",
        "    nn.Dropout(p=0.2),\n",
        "    nn.Linear(64, 1),\n",
        "    nn.Sigmoid()\n",
        ").to(device)\n",
        "\n",
        "X_mean = X.mean(axis=0)\n",
        "X_std = X.std(axis=0) + 1e-8\n",
        "X_norm = (X - X_mean) / X_std\n",
        "y_norm = normalize(y)\n",
        "\n",
        "X_tensor = torch.tensor(X_norm, dtype=torch.float32)\n",
        "y_tensor = torch.tensor(y_norm.reshape(-1, 1), dtype=torch.float32)\n",
        "\n",
        "dataset = TensorDataset(X_tensor, y_tensor)\n",
        "train_size = int(0.8 * len(dataset))\n",
        "val_size = len(dataset) - train_size\n",
        "train_ds, val_ds = random_split(dataset, [train_size, val_size])\n",
        "\n",
        "train_loader = DataLoader(\n",
        "    train_ds, batch_size=1024, shuffle=True,\n",
        "    num_workers=2, pin_memory=True, drop_last=True\n",
        ")\n",
        "val_loader = DataLoader(\n",
        "    val_ds, batch_size=1024,\n",
        "    num_workers=2, pin_memory=True\n",
        ")\n",
        "\n",
        "optimizer_dropout = optim.Adam(model_deep_dropout.parameters(), lr=1e-3)\n",
        "criterion = nn.MSELoss()\n",
        "\n",
        "metric = nn.MSELoss()\n",
        "\n",
        "train_mse_dropout, val_mse_dropout = train_and_validate(\n",
        "    model=model_deep_dropout,\n",
        "    optimizer=optimizer_dropout,\n",
        "    criterion=criterion,\n",
        "    metric=metric,\n",
        "    train_loader=train_loader,\n",
        "    val_loader=val_loader,\n",
        "    num_epochs=10\n",
        ")\n",
        "\n",
        "print(f\"[Deep + Dropout] MSE_val: {val_mse_dropout:.4f}\")\n",
        "\n",
        "model_deep_dropout.eval()\n",
        "X_val_batch, y_val_batch = next(iter(val_loader))\n",
        "X_val_batch = X_val_batch.to(device)\n",
        "with torch.no_grad():\n",
        "    y_pred_norm = model_deep_dropout(X_val_batch).squeeze().cpu().numpy()\n",
        "\n",
        "y_pred_real = denormalize(y_pred_norm)\n",
        "y_val_real = denormalize(y_val_batch.squeeze().cpu().numpy())\n",
        "val_mse_real_dropout = np.mean((y_pred_real - y_val_real) ** 2)\n",
        "print(f\"[Deep + Dropout] MSE_val (в годах): {val_mse_real_dropout:.2f}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "9dcbadcc",
      "metadata": {
        "id": "9dcbadcc"
      },
      "source": [
        "**Задание 2.4 (1.5 балла).** Теперь, когда мы определились с выбором архитектуры нейронной сети, пора заняться рутиной DL-инженера &mdash; перебором гиперпараметров. Подберите оптимальное значение lr по значению MSE на валидации (по логарифмической сетке, достаточно посмотреть 3-4 значения), можете воспользоваться `verbose=False` в функции `train_and_validate`.\n",
        "\n",
        "Также подберем оптимальное значение параметра weight decay для данного lr. Weight decay &mdash; это аналог L2-регуляризации для нейронных сетей. Почитать о нем можно, например, [здесь](https://paperswithcode.com/method/weight-decay). В PyTorch он задается как параметр оптимизатора `weight_decay`. Подберите оптимальное значение weight decay по логарифимической сетке (его типичные значения лежат в диапазоне $[10^{-6}, 10^{-3}]$, но не забудьте включить нулевое значение в сетку).\n",
        "\n",
        "Постройте графики зависимости MSE на трейне и на валидации от значений параметров. Прокомментируйте получившиеся зависимости."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "8UqadoheOQSu",
      "metadata": {
        "id": "8UqadoheOQSu"
      },
      "outputs": [],
      "source": [
        "# YOUR CODE HERE (－.－)...zzzZZZzzzZZZ"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "8nk3dvibo6SE",
      "metadata": {
        "id": "8nk3dvibo6SE"
      },
      "source": [
        "Как вы могли заметить, еще одна рутина DL-инженера &mdash; утомительное ожидание обучения моделей.\n",
        "\n",
        "**Задание 2.5 (0.5 балла).** Мы провели большое число экспериментов и подобрали оптимальную архитектуру и гиперпараметры. Пришло время обучить модель на полной обучающей выборке, померять качество на тестовой выборке и сравнить с бейзлайнами. Проделайте это."
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "TNg7PqWZD_-2"
      },
      "id": "TNg7PqWZD_-2",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "pR4FJ4PYYajk",
      "metadata": {
        "id": "pR4FJ4PYYajk"
      },
      "outputs": [],
      "source": [
        "# YOUR CODE HERE (－.－)...zzzZZZzzzZZZ"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Кото-пост (0.1 балл)"
      ],
      "metadata": {
        "id": "T3BxhZSDD5fO"
      },
      "id": "T3BxhZSDD5fO"
    },
    {
      "cell_type": "markdown",
      "source": [
        "Поделитесь эмоциями от практики и не забудьте прикрепить фотографию вашего помощника в этом домашнем задании!"
      ],
      "metadata": {
        "id": "EN7Co7ojEhlm"
      },
      "id": "EN7Co7ojEhlm"
    },
    {
      "cell_type": "markdown",
      "source": [
        "..."
      ],
      "metadata": {
        "id": "sfPI13fvEtFv"
      },
      "id": "sfPI13fvEtFv"
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.4"
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 5
}