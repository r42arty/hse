{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/r42arty/hse/blob/main/mod3/DL/DL_1.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Основы машинного обучения, ИИМУП\n",
        "\n",
        "## НИУ ВШЭ, 2024-25 учебный год"
      ],
      "metadata": {
        "id": "uzoPPj-CT-hG"
      },
      "id": "uzoPPj-CT-hG"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VRUsuZR2cQoY"
      },
      "source": [
        "# Домашнее задание 1: Полносвязные нейронные сети"
      ],
      "id": "VRUsuZR2cQoY"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lV9pvgZJTYGj"
      },
      "source": [
        "Задание выполнил(а):\n",
        "\n",
        "    (впишите свои фамилию и имя)"
      ],
      "id": "lV9pvgZJTYGj"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZML8VxlPTYGj"
      },
      "source": [
        "## Общая информация"
      ],
      "id": "ZML8VxlPTYGj"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nTmiXfZZTYGl"
      },
      "source": [
        "__Внимание!__  \n",
        "\n",
        "\n",
        "* Домашнее задание выполняется самостоятельно\n",
        "* Не допускается помощь в решении домашнего задания от однокурсников или третьих лиц. «Похожие» решения считаются плагиатом, и все задействованные студенты — в том числе и те, у кого списали, — не могут получить за него больше 0 баллов\n",
        "* Использование в решении домашнего задания генеративных моделей (ChatGPT и так далее) за рамками справочной и образовательной информации для генерации кода задания — считается плагиатом, и такое домашнее задание оценивается в 0 баллов\n",
        "* Старайтесь сделать код как можно более оптимальным. В частности, будет штрафоваться использование циклов в тех случаях, когда операцию можно совершить при помощи инструментов библиотек, о которых рассказывалось в курсе"
      ],
      "id": "nTmiXfZZTYGl"
    },
    {
      "cell_type": "markdown",
      "id": "lonely-delta",
      "metadata": {
        "id": "lonely-delta",
        "pycharm": {
          "name": "#%% md\n"
        }
      },
      "source": [
        "## О задании\n",
        "\n",
        "В этом задании вам предстоит обучить полносвязную нейронную сеть для предсказания года выпуска песни по ее аудио-признакам. Для этого мы будем использовать [Million Songs Dataset](https://samyzaf.com/ML/song_year/song_year.html)."
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Импорт библиотек и загрузка данных"
      ],
      "metadata": {
        "id": "qMsTUDdFCv-x"
      },
      "id": "qMsTUDdFCv-x"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "lonely-component",
      "metadata": {
        "id": "lonely-component",
        "pycharm": {
          "name": "#%%\n"
        }
      },
      "outputs": [],
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import seaborn as sns\n",
        "import torch\n",
        "\n",
        "from IPython.display import clear_output\n",
        "from sklearn.linear_model import Ridge\n",
        "from sklearn.metrics import mean_squared_error\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from torch import nn\n",
        "from torch.utils.data import DataLoader, TensorDataset\n",
        "from tqdm.notebook import tqdm"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "plt.rcParams.update({\"font.size\": 16})\n",
        "sns.set_style(\"whitegrid\")\n",
        "np.random.seed(0xFA1AFE1)"
      ],
      "metadata": {
        "id": "lYtG-wqYCsqj"
      },
      "id": "lYtG-wqYCsqj",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "id": "marine-logistics",
      "metadata": {
        "id": "marine-logistics"
      },
      "source": [
        "Начнем с того, что скачаем и загрузим данные:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "bridal-archive",
      "metadata": {
        "id": "bridal-archive"
      },
      "outputs": [],
      "source": [
        "!wget -O data.txt.zip https://archive.ics.uci.edu/ml/machine-learning-databases/00203/YearPredictionMSD.txt.zip"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "welsh-heavy",
      "metadata": {
        "id": "welsh-heavy"
      },
      "outputs": [],
      "source": [
        "df = pd.read_csv(\"data.txt.zip\", header=None)\n",
        "df"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "single-hearts",
      "metadata": {
        "id": "single-hearts"
      },
      "source": [
        "Посмотрим на статистики по данным."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "interior-bacteria",
      "metadata": {
        "id": "interior-bacteria"
      },
      "outputs": [],
      "source": [
        "df.describe()"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "broad-writer",
      "metadata": {
        "id": "broad-writer"
      },
      "source": [
        "Целевая переменная, год выпуска песни, записана в первом столбце. Посмотрим на ее распределение."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "exposed-small",
      "metadata": {
        "id": "exposed-small"
      },
      "outputs": [],
      "source": [
        "plt.hist(df.iloc[:, 0], bins=20)\n",
        "plt.xlabel(\"year\")\n",
        "plt.ylabel(\"count\")\n",
        "plt.show()\n",
        "print(f\"Range: {df.iloc[:, 0].min()} - {df.iloc[:, 0].max()}\")\n",
        "print(f\"Unique values: {np.unique(df.iloc[:, 0]).size}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "noted-rebecca",
      "metadata": {
        "id": "noted-rebecca"
      },
      "source": [
        "Разобьем данные на обучение и тест (не меняйте здесь ничего, чтобы сплит был одинаковым у всех)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "presidential-wisconsin",
      "metadata": {
        "id": "presidential-wisconsin"
      },
      "outputs": [],
      "source": [
        "X = df.iloc[:, 1:].values\n",
        "y = df.iloc[:, 0].values\n",
        "\n",
        "train_size = int(0.75 * X.shape[0])\n",
        "X_train = X[:train_size, :]\n",
        "y_train = y[:train_size]\n",
        "X_test = X[train_size:, :]\n",
        "y_test = y[train_size:]\n",
        "X_train.shape, X_test.shape"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "adaptive-quantity",
      "metadata": {
        "id": "adaptive-quantity"
      },
      "source": [
        "**Задание 0 (0 баллов, но при невыполнении максимальная оценка за всю работу &mdash; 0 баллов).** Мы будем использовать MSE как метрику качества. Прежде чем обучать нейронные сети, нам нужно проверить несколько простых бейзлайнов, чтобы было с чем сравнить более сложные алгоритмы. Для этого бучите `Ridge` регрессию из `sklearn`. Кроме того, посчитайте качество при наилучшем константном прогнозе (также пропишите текстом, какая константа будет лучшей для MSE)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "mexican-fireplace",
      "metadata": {
        "id": "mexican-fireplace"
      },
      "outputs": [],
      "source": [
        "# YOUR CODE HERE (－.－)...zzzZZZzzzZZZ"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "0f4c6b65",
      "metadata": {
        "id": "0f4c6b65"
      },
      "source": [
        "**Ответ:** ..."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "suspected-arbitration",
      "metadata": {
        "id": "suspected-arbitration"
      },
      "source": [
        "Теперь приступим к экспериментам с нейросетями. Для начала отделим от данных валидацию:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "offensive-publication",
      "metadata": {
        "id": "offensive-publication"
      },
      "outputs": [],
      "source": [
        "X_train, X_val, y_train, y_val = train_test_split(\n",
        "    X_train, y_train, test_size=0.25, random_state=0xE2E4\n",
        ")\n",
        "X_train.shape, X_val.shape"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "modern-platform",
      "metadata": {
        "id": "modern-platform"
      },
      "source": [
        "## Глава I. Заводим нейронную сеть (5 баллов)\n",
        "\n",
        "**Задание 1.1 (0.5 баллов).** Заполните пропуски в функции `train_and_validate`. Она поможет нам запускать эксперименты. Можете также реализовать поддержку обучения на GPU, чтобы эксперименты считались быстрее. Бесплатно воспользоваться GPU можно на сервисах **Google Colab** и **Kaggle**."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "cooperative-bedroom",
      "metadata": {
        "id": "cooperative-bedroom"
      },
      "outputs": [],
      "source": [
        "def plot_losses(train_losses, train_metrics, val_losses, val_metrics):\n",
        "    \"\"\"\n",
        "    Plot losses and metrics while training\n",
        "      - train_losses: sequence of train losses\n",
        "      - train_metrics: sequence of train MSE values\n",
        "      - val_losses: sequence of validation losses\n",
        "      - val_metrics: sequence of validation MSE values\n",
        "    \"\"\"\n",
        "    clear_output()\n",
        "    fig, axs = plt.subplots(1, 2, figsize=(15, 5))\n",
        "    axs[0].plot(range(1, len(train_losses) + 1), train_losses, label=\"train\")\n",
        "    axs[0].plot(range(1, len(val_losses) + 1), val_losses, label=\"val\")\n",
        "    axs[1].plot(range(1, len(train_metrics) + 1), train_metrics, label=\"train\")\n",
        "    axs[1].plot(range(1, len(val_metrics) + 1), val_metrics, label=\"val\")\n",
        "\n",
        "    if max(train_losses) / min(train_losses) > 10:\n",
        "        axs[0].set_yscale(\"log\")\n",
        "\n",
        "    if max(train_metrics) / min(train_metrics) > 10:\n",
        "        axs[0].set_yscale(\"log\")\n",
        "\n",
        "    for ax in axs:\n",
        "        ax.set_xlabel(\"epoch\")\n",
        "        ax.legend()\n",
        "\n",
        "    axs[0].set_ylabel(\"loss\")\n",
        "    axs[1].set_ylabel(\"MSE\")\n",
        "    plt.show()\n",
        "\n",
        "\n",
        "def train_and_validate(\n",
        "    model,\n",
        "    optimizer,\n",
        "    criterion,\n",
        "    metric,\n",
        "    train_loader,\n",
        "    val_loader,\n",
        "    num_epochs,\n",
        "    verbose=True,\n",
        "):\n",
        "    \"\"\"\n",
        "    Train and validate neural network\n",
        "      - model: neural network to train\n",
        "      - optimizer: optimizer chained to a model\n",
        "      - criterion: loss function class\n",
        "      - metric: function to measure MSE taking neural networks predictions\n",
        "                 and ground truth labels\n",
        "      - train_loader: DataLoader with train set\n",
        "      - val_loader: DataLoader with validation set\n",
        "      - num_epochs: number of epochs to train\n",
        "      - verbose: whether to plot metrics during training\n",
        "    Returns:\n",
        "      - train_mse: training MSE over the last epoch\n",
        "      - val_mse: validation MSE after the last epoch\n",
        "    \"\"\"\n",
        "    train_losses, val_losses = [], []\n",
        "    train_metrics, val_metrics = [], []\n",
        "\n",
        "    for epoch in range(1, num_epochs + 1):\n",
        "        model.train()\n",
        "        running_loss, running_metric = 0, 0\n",
        "        pbar = (\n",
        "            tqdm(train_loader, desc=f\"Training {epoch}/{num_epochs}\")\n",
        "            if verbose\n",
        "            else train_loader\n",
        "        )\n",
        "\n",
        "        for i, (X_batch, y_batch) in enumerate(pbar, 1):\n",
        "            \"\"\"\n",
        "            YOUR CODE HERE (－.－)...zzzZZZzzzZZZ\n",
        "            Do forward and backward passes\n",
        "            predictions = ...\n",
        "            loss = ...\n",
        "            \"\"\"\n",
        "\n",
        "            with torch.no_grad():\n",
        "                metric_value = metric(predictions, y_batch)\n",
        "                if type(metric_value) == torch.Tensor:\n",
        "                    metric_value = metric_value.item()\n",
        "                running_loss += loss.item() * X_batch.shape[0]\n",
        "                running_metric += metric_value * X_batch.shape[0]\n",
        "\n",
        "            if verbose and i % 100 == 0:\n",
        "                pbar.set_postfix({\"loss\": loss.item(), \"MSE\": metric_value})\n",
        "\n",
        "        train_losses += [running_loss / len(train_loader.dataset)]\n",
        "        train_metrics += [running_metric / len(train_loader.dataset)]\n",
        "\n",
        "        model.eval()\n",
        "        running_loss, running_metric = 0, 0\n",
        "        pbar = (\n",
        "            tqdm(val_loader, desc=f\"Validating {epoch}/{num_epochs}\")\n",
        "            if verbose\n",
        "            else val_loader\n",
        "        )\n",
        "\n",
        "        for i, (X_batch, y_batch) in enumerate(pbar, 1):\n",
        "            with torch.no_grad():\n",
        "                \"\"\"\n",
        "                YOUR CODE HERE (－.－)...zzzZZZzzzZZZ\n",
        "                Do evaluation\n",
        "                predictions = ...\n",
        "                loss = ...\n",
        "                \"\"\"\n",
        "\n",
        "                metric_value = metric(predictions, y_batch)\n",
        "                if type(metric_value) == torch.Tensor:\n",
        "                    metric_value = metric_value.item()\n",
        "                running_loss += loss.item() * X_batch.shape[0]\n",
        "                running_metric += metric_value * X_batch.shape[0]\n",
        "\n",
        "            if verbose and i % 100 == 0:\n",
        "                pbar.set_postfix({\"loss\": loss.item(), \"MSE\": metric_value})\n",
        "\n",
        "        val_losses += [running_loss / len(val_loader.dataset)]\n",
        "        val_metrics += [running_metric / len(val_loader.dataset)]\n",
        "\n",
        "        if verbose:\n",
        "            plot_losses(train_losses, train_metrics, val_losses, val_metrics)\n",
        "\n",
        "    if verbose:\n",
        "        print(f\"Validation MSE: {val_metrics[-1]:.3f}\")\n",
        "\n",
        "    return train_metrics[-1], val_metrics[-1]"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "adjacent-grace",
      "metadata": {
        "id": "adjacent-grace"
      },
      "source": [
        "**Задание 1.2 (0.75 балла).** Попробуем обучить нашу первую нейронную сеть. Здесь целевая переменная дискретная &mdash; это год выпуска песни. Поэтому будем учить сеть на классификацию c помощью [кросс-энтропийной функции потерь](https://pytorch.org/docs/stable/generated/torch.nn.CrossEntropyLoss.html).\n",
        "\n",
        "- В качестве архитектуры сети возьмите два линейных слоя с активацией ReLU между ними c числом скрытых нейронов, равным 128.\n",
        "- Используйте SGD с `lr=1e-2`.\n",
        "- Возьмите размер мини-батча около 32-64, примерно 3-4 эпох обучения должно быть достаточно.\n",
        "- Скорее всего вам пригодится `torch.utils.data.TensorDataset`. Когда будете конвертировать numpy-массивы в torch-тензоры, используйте тип `torch.float32`.\n",
        "- Также преобразуйте целевую переменную так, чтобы ее значения принимали значения от $0$ до $C-1$, где $C$ &mdash; число классов (лучше передайте преобразованное значение в TensorDataset, исходное нам еще пригодится)\n",
        "- В качестве параметра `metric` в `train_and_validate` передайте lambda-выражение, которое считает MSE по выходу нейронной сети и целевой переменной. В случае классификации предсказывается класс с наибольшей вероятностью (или, что то же самое, с наибольшим значением **логита**$^1$).\n",
        "\n",
        "$^1$ **Логит** &mdash; выход последнего линейного слоя, может принимать любые вещественные значения. Если применить Softmax к логитам, то получатся вероятности распределения классов."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "manufactured-beverage",
      "metadata": {
        "id": "manufactured-beverage"
      },
      "outputs": [],
      "source": [
        "# YOUR CODE HERE (－.－)...zzzZZZzzzZZZ"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "postal-kingdom",
      "metadata": {
        "id": "postal-kingdom"
      },
      "source": [
        "**Задание 1.3 (0.5 балла).** Прокомментируйте ваши наблюдения. Удалось ли побить бейзлайн? Как вы думаете, хорошая ли идея учить классификатор для этой задачи? Почему?\n",
        "\n",
        "**Ответ:** ..."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "gorgeous-italy",
      "metadata": {
        "id": "gorgeous-italy"
      },
      "source": [
        "**Задание 1.4 (0.75 балла).** Теперь попробуем решать задачу как регрессию. Обучите нейронную сеть на [MSE](https://pytorch.org/docs/stable/generated/torch.nn.MSELoss.html).\n",
        "\n",
        "- Используйте такие же гиперпараметры обучения.\n",
        "- Когда передаете целевую переменную в TensorDataset, сделайте reshape в (-1, 1).\n",
        "- Не забудьте изменить lambda-выражение, которые вы передаете в `train_and_validate`.\n",
        "- Если что-то пойдет не так, можете попробовать меньшие значения `lr`."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "contrary-justice",
      "metadata": {
        "id": "contrary-justice"
      },
      "outputs": [],
      "source": [
        "# YOUR CODE HERE (－.－)...zzzZZZzzzZZZ"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "nonprofit-passenger",
      "metadata": {
        "id": "nonprofit-passenger"
      },
      "source": [
        "**Задание 1.5 (0.5 балла).** Получилось ли у вас стабилизировать обучение? Помогли ли меньшие значения `lr`? Стало ли лучше от замены классификации на регрессию? Как вы думаете, почему так происходит? В качестве подсказки можете посмотреть на распределение целевой переменной и магнитуду значений признаков.\n",
        "\n",
        "**Ответ:** ..."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "tested-cleaners",
      "metadata": {
        "id": "tested-cleaners"
      },
      "source": [
        "**Задание 1.6 (0.75 балла).** Начнем с того, что попробуем отнормировать целевую переменную. Для этого воспользуемся min-max нормализацией, чтобы целевая переменная принимала значения от 0 до 1. Реализуйте функции `normalize` и `denormalize`, которые, соответственно, нормируют целевую переменную и применяют обратное преобразование. Минимум и максимум оцените по обучающей выборке (то есть эти константы должны быть фиксированными и не зависеть от передаваемой выборки)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "downtown-stake",
      "metadata": {
        "id": "downtown-stake"
      },
      "outputs": [],
      "source": [
        "def normalize(sample):\n",
        "    \"\"\"\n",
        "    Min-max normalization to convert sample to [0, 1] range\n",
        "    \"\"\"\n",
        "    # YOUR CODE HERE (－.－)...zzzZZZzzzZZZ\n",
        "    pass\n",
        "\n",
        "\n",
        "def denormalize(sample):\n",
        "    \"\"\"\n",
        "    Denormalize sample from [0, 1] to initial range\n",
        "    \"\"\"\n",
        "    # YOUR CODE HERE (－.－)...zzzZZZzzzZZZ\n",
        "    pass"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "official-booking",
      "metadata": {
        "id": "official-booking"
      },
      "source": [
        "Теперь повторите эксперимент из **задания 1.4**, обучаясь на нормированной целевой переменной. Сделаем также еще одно изменение: добавим [сигмоидную активацию](https://pytorch.org/docs/stable/generated/torch.nn.Sigmoid.html) после последнего линейного слоя сети. Таким образом мы гарантируем, что нейронная сеть предсказывает числа из промежутка $[0, 1]$. Использование активации - довольно распространенный прием, когда мы хотим получить числа из определенного диапазона значений."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "olive-brick",
      "metadata": {
        "id": "olive-brick"
      },
      "outputs": [],
      "source": [
        "# YOUR CODE HERE (－.－)...zzzZZZzzzZZZ"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "twenty-pulse",
      "metadata": {
        "id": "twenty-pulse"
      },
      "source": [
        "**Задание 1.7 (0.5 балла).** Сравните результаты этого эксперимента с предыдущим запуском.\n",
        "\n",
        "**Ответ:** ..."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "colonial-slovakia",
      "metadata": {
        "id": "colonial-slovakia"
      },
      "source": [
        "**Задание 1.8 (0.75 балла).** На этот раз попробуем отнормировать не только целевую переменную, но и сами данные, которые подаются сети на вход. Для них будем использовать нормализацию через среднее и стандартное отклонение. Преобразуйте данные и повторите прошлый эксперимент. Скорее всего, имеет смысл увеличить число эпох обучения."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "prospective-disabled",
      "metadata": {
        "id": "prospective-disabled"
      },
      "outputs": [],
      "source": [
        "# YOUR CODE HERE (－.－)...zzzZZZzzzZZZ"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "opponent-decision",
      "metadata": {
        "id": "opponent-decision"
      },
      "source": [
        "Если вы все сделали правильно, то у вас должно было получиться качество, сравнимое с `Ridge` регрессией.\n",
        "\n",
        "**Мораль:** как видите, нам пришлось сделать очень много хитрых телодвижений, чтобы нейронная сеть работала хотя бы так же, как и простая линейная модель. Здесь, конечно, показан совсем экстремальный случай, когда без нормализации данных нейронная сеть просто не учится. Как правило, в реальности завести нейронную сеть из коробки не очень сложно, но вот заставить ее работать на полную &mdash; куда более трудоемкая задача. Написание пайплайнов обучения нейросетевых моделей требует большой аккуратности, а дебаг часто превращается в угадайку. К счастью, очень часто на помощь приходит интуиция, и мы надеемся, что вы сможете выработать ее со временем!\n",
        "\n",
        "Начнем с двух советов, которые стоит принять на вооружение:\n",
        "\n",
        "- Обязательно начинаем любые эксперименты с бейзлайнов: без них мы бы не поняли, что нейронная сеть не учится в принципе\n",
        "- При постановке эксперментов старайтесь делать минимальное количество изменений за раз (в идеале одно!): только так можно понять, какие конкретно изменения влияют на результат"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "royal-cholesterol",
      "metadata": {
        "id": "royal-cholesterol"
      },
      "source": [
        "## Часть 2. Улучшаем нейронную сеть (5 баллов)\n",
        "\n",
        "Продолжим экспериментировать с нейронной сетью, чтобы добиться еще лучшего качества."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "ignored-active",
      "metadata": {
        "id": "ignored-active"
      },
      "source": [
        "**Задание 2.1 (1 балл).** Давайте попробуем другие оптимизаторы. Обучите нейросеть с помощью SGD+momentum и Adam. Опишите свои наблюдения и в дальнейших запусках используйте лучший оптимизатор. Для Adam обычно берут learning rate поменьше, в районе $10^{-3}$."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "eastern-gnome",
      "metadata": {
        "id": "eastern-gnome"
      },
      "outputs": [],
      "source": [
        "# YOUR CODE HERE (－.－)...zzzZZZzzzZZZ"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "hispanic-postage",
      "metadata": {
        "id": "hispanic-postage"
      },
      "source": [
        "**Задание 2.2 (1 балл).** Теперь сделаем нашу нейронную сеть более сложной. Попробуйте сделать сеть:\n",
        "\n",
        "- более широкой (то есть увеличить размерность скрытого слоя, например, вдвое)\n",
        "- более глубокой (то есть добавить еще один скрытый слой)\n",
        "\n",
        "Опишите, как увеличение числа параметров модели влияет на качество на обучающей и валидационной выборках."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "1d466362",
      "metadata": {
        "id": "1d466362"
      },
      "outputs": [],
      "source": [
        "# YOUR CODE HERE (－.－)...zzzZZZzzzZZZ"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "454acdb1",
      "metadata": {
        "id": "454acdb1"
      },
      "source": [
        "**Задание 2.3 (1 балл).** Как вы должны были заметить, более сложная модель стала сильнее переобучаться. Попробуем добавить в обучение регуляризацию, чтобы бороться с переобучением. Добавьте слой дропаута ([`nn.Dropout`](https://pytorch.org/docs/stable/generated/torch.nn.Dropout.html#torch.nn.Dropout)) с параметром $p=0.2$ после каждого линейного слоя, кроме последнего. Почитать про дропаут можете в следующем [блогпосте](https://medium.com/@amarbudhiraja/https-medium-com-amarbudhiraja-learning-less-to-learn-better-dropout-in-deep-machine-learning-74334da4bfc5) или в оригинальной [статье](https://jmlr.org/papers/volume15/srivastava14a/srivastava14a.pdf)\n",
        "\n",
        "Опишите результаты."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "483a941a",
      "metadata": {
        "id": "483a941a"
      },
      "outputs": [],
      "source": [
        "# YOUR CODE HERE (－.－)...zzzZZZzzzZZZ"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "9dcbadcc",
      "metadata": {
        "id": "9dcbadcc"
      },
      "source": [
        "**Задание 2.4 (1.5 балла).** Теперь, когда мы определились с выбором архитектуры нейронной сети, пора заняться рутиной DL-инженера &mdash; перебором гиперпараметров. Подберите оптимальное значение lr по значению MSE на валидации (по логарифмической сетке, достаточно посмотреть 3-4 значения), можете воспользоваться `verbose=False` в функции `train_and_validate`.\n",
        "\n",
        "Также подберем оптимальное значение параметра weight decay для данного lr. Weight decay &mdash; это аналог L2-регуляризации для нейронных сетей. Почитать о нем можно, например, [здесь](https://paperswithcode.com/method/weight-decay). В PyTorch он задается как параметр оптимизатора `weight_decay`. Подберите оптимальное значение weight decay по логарифимической сетке (его типичные значения лежат в диапазоне $[10^{-6}, 10^{-3}]$, но не забудьте включить нулевое значение в сетку).\n",
        "\n",
        "Постройте графики зависимости MSE на трейне и на валидации от значений параметров. Прокомментируйте получившиеся зависимости."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "8UqadoheOQSu",
      "metadata": {
        "id": "8UqadoheOQSu"
      },
      "outputs": [],
      "source": [
        "# YOUR CODE HERE (－.－)...zzzZZZzzzZZZ"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "8nk3dvibo6SE",
      "metadata": {
        "id": "8nk3dvibo6SE"
      },
      "source": [
        "Как вы могли заметить, еще одна рутина DL-инженера &mdash; утомительное ожидание обучения моделей.\n",
        "\n",
        "**Задание 2.5 (0.5 балла).** Мы провели большое число экспериментов и подобрали оптимальную архитектуру и гиперпараметры. Пришло время обучить модель на полной обучающей выборке, померять качество на тестовой выборке и сравнить с бейзлайнами. Проделайте это."
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "TNg7PqWZD_-2"
      },
      "id": "TNg7PqWZD_-2",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "pR4FJ4PYYajk",
      "metadata": {
        "id": "pR4FJ4PYYajk"
      },
      "outputs": [],
      "source": [
        "# YOUR CODE HERE (－.－)...zzzZZZzzzZZZ"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Кото-пост (0.1 балл)"
      ],
      "metadata": {
        "id": "T3BxhZSDD5fO"
      },
      "id": "T3BxhZSDD5fO"
    },
    {
      "cell_type": "markdown",
      "source": [
        "Поделитесь эмоциями от практики и не забудьте прикрепить фотографию вашего помощника в этом домашнем задании!"
      ],
      "metadata": {
        "id": "EN7Co7ojEhlm"
      },
      "id": "EN7Co7ojEhlm"
    },
    {
      "cell_type": "markdown",
      "source": [
        "..."
      ],
      "metadata": {
        "id": "sfPI13fvEtFv"
      },
      "id": "sfPI13fvEtFv"
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.4"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}